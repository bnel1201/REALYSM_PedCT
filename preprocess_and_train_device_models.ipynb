{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef881466",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mshutil\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil_classifier_pediatric\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mutil_classifier_pediatric\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mutil\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil_preprocessing\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mutil_preprocessing\u001b[39;00m\n",
      "File \u001b[0;32m~/Dev/REALYSM_peds/util/util_classifier_pediatric.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01moptim\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "import util\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import shutil\n",
    "import re\n",
    "import util.util_classifier_pediatric as util_classifier_pediatric\n",
    "import util.util as util\n",
    "import util.util_preprocessing as util_preprocessing\n",
    "import util.util_testing as util_testing\n",
    "from tqdm import tqdm\n",
    "import util.config as config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2ee4214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(util)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409270c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6d14803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Processing /home/brandon.nelson/tqdm-4.66.1-py3-none-any.whl\n",
      "Installing collected packages: tqdm\n",
      "Successfully installed tqdm-4.66.1\n"
     ]
    }
   ],
   "source": [
    "!pip install ~/tqdm-4.66.1-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8e8965",
   "metadata": {},
   "outputs": [],
   "source": [
    "DENSITY = \"fatty\"\n",
    "SIZE = \"7.0\"\n",
    "LESIONDENSITY = \"1.06\"\n",
    "DETECTOR = \"SIM\"\n",
    "DOSE = \"2.22e10\"\n",
    "l_detectorTypes = [DETECTOR]\n",
    "\n",
    "sourceDir00,sourceDir0 = util_preprocessing.get_source_dirs(config.dir_training_data,LESIONDENSITY,DENSITY,SIZE,DETECTOR,DOSE)\n",
    "saveDir00 = util_preprocessing.get_save_dir(config.dir_training_data_preprocessed, DENSITY,SIZE,LESIONDENSITY,DOSE,DETECTOR)\n",
    "nickname = util_preprocessing.get_model_nickname(DENSITY,SIZE,DETECTOR,LESIONDENSITY,DOSE)\n",
    "saveDir00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e206683",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_images = True\n",
    "split_train_test = True\n",
    "train_classifier = True\n",
    "create_evaluations_dicts = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ee6ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copy the images and create the \"annotation.txt\"\n",
    "if preprocess_images:\n",
    "    saveDir = saveDir00\n",
    "    saveDir_images = saveDir + \"/\" + \"images/\"\n",
    "    os.makedirs(saveDir_images, exist_ok=True)\n",
    "    annotationsFile = saveDir + \"/annotations.txt\"\n",
    "\n",
    "    annotations_list = []\n",
    "    for detectorType in l_detectorTypes:\n",
    "        examples = glob.glob(sourceDir0 + \"/*/*/projection_DM*.raw\")\n",
    "        for example in tqdm(examples):\n",
    "            saveName = (\n",
    "                example.replace(sourceDir00, \"\")\n",
    "                .replace(\"/\", \"_\")\n",
    "                .replace(\".raw\", \"\")\n",
    "            )\n",
    "            file_outputProjection = (\n",
    "                os.path.dirname(example) + \"/\" + \"output_projection.out\"\n",
    "            )\n",
    "            stringToSearch = \"adipose\"\n",
    "            all_results = util.searchForLine(file_outputProjection, stringToSearch)\n",
    "            dose = float(all_results[1].split(\"\\t\")[2])\n",
    "            # print('DOSE ' + str(dose))\n",
    "            filename_mhd = example.replace(\".raw\", \".mhd\")\n",
    "\n",
    "            lesion_present = util_preprocessing.get_lesion_label(filename_mhd)\n",
    "            if lesion_present > 0:\n",
    "                label = \"lesion\"\n",
    "            else:\n",
    "                label = \"nolesion\"\n",
    "\n",
    "            # read image\n",
    "            savePath = example.replace(sourceDir00, saveDir00).replace(\n",
    "                \".raw\", \".png\"\n",
    "            )\n",
    "            tmp = util_preprocessing.preprocess_raw_file(filename_mhd)\n",
    "            np.save(saveDir_images + \"/\" + saveName + \".npy\", tmp)\n",
    "\n",
    "            annotation = (\n",
    "                saveName\n",
    "                + \".npy\"\n",
    "                + \" \"\n",
    "                + str(DENSITY)\n",
    "                + \" \"\n",
    "                + str(detectorType)\n",
    "                + \" \"\n",
    "                + str(dose)\n",
    "                + \" \"\n",
    "                + label\n",
    "            )\n",
    "            annotations_list.append(annotation)\n",
    "\n",
    "    with open(annotationsFile, \"w\") as f:\n",
    "        for line in annotations_list:\n",
    "            f.write(f\"{line}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f0fd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "if split_train_test:\n",
    "    dirPath = saveDir00\n",
    "    saveDir_trainValTest = dirPath + \"_basic_train_val_test/\"\n",
    "\n",
    "    flImages = open(dirPath + \"annotations.txt\", \"r\")\n",
    "    lines = flImages.readlines()\n",
    "    flImages.close()\n",
    "\n",
    "    \n",
    "    lines = [line.strip() for line in lines]\n",
    "    print(lines[0])\n",
    "\n",
    "    lines_notP = [lines[i] for i in range(len(lines)) if i < int(len(lines)*0.7)] # %70 training\n",
    "    print(len(lines_notP))\n",
    "\n",
    "    lines_P = [lines[i] for i in range(len(lines)) if (i >= int(len(lines)*0.7) and i < int(len(lines)*0.85))] # %15 validation\n",
    "    print(len(lines_P))\n",
    "\n",
    "\n",
    "    lines_P_t = [lines[i] for i in range(len(lines)) if i >= int(len(lines)*0.85)] # %15 test\n",
    "    print(len(lines_P_t))\n",
    "\n",
    "\n",
    "    x_train = lines_notP\n",
    "    x_val = lines_P\n",
    "    x_test = lines_P_t\n",
    "\n",
    "    os.makedirs(saveDir_trainValTest, exist_ok=True)\n",
    "    os.makedirs(saveDir_trainValTest + \"/train/withlesion/\", exist_ok=True)\n",
    "    os.makedirs(saveDir_trainValTest + \"/train/nolesion/\", exist_ok=True)\n",
    "    os.makedirs(saveDir_trainValTest + \"/val/withlesion/\", exist_ok=True)\n",
    "    os.makedirs(saveDir_trainValTest + \"/val/nolesion/\", exist_ok=True)\n",
    "    os.makedirs(saveDir_trainValTest + \"/test/withlesion/\", exist_ok=True)\n",
    "    os.makedirs(saveDir_trainValTest + \"/test/nolesion/\", exist_ok=True)\n",
    "\n",
    "    for i in tqdm(range(len(x_train))):\n",
    "        line = x_train[i]\n",
    "        imgname = line.split(\" \")[0]\n",
    "        if not os.path.isfile(dirPath + \"images/\" + imgname):\n",
    "            print(\"PROBLEM\")\n",
    "        if \"nolesion\" in line:\n",
    "            shutil.copyfile(\n",
    "                dirPath + \"images/\" + imgname,\n",
    "                saveDir_trainValTest + \"/train/nolesion/\" + imgname,\n",
    "            )\n",
    "        else:\n",
    "            shutil.copyfile(\n",
    "                dirPath + \"images/\" + imgname,\n",
    "                saveDir_trainValTest + \"/train/withlesion/\" + imgname,\n",
    "            )\n",
    "\n",
    "    for i in tqdm(range(len(x_val))):\n",
    "        line = x_val[i]\n",
    "        imgname = line.split(\" \")[0]\n",
    "        if not os.path.isfile(dirPath + \"images/\" + imgname):\n",
    "            print(\"PROBLEM\")\n",
    "        if \"nolesion\" in line:\n",
    "            shutil.copyfile(\n",
    "                dirPath + \"images/\" + imgname,\n",
    "                saveDir_trainValTest + \"/val/nolesion/\" + imgname,\n",
    "            )\n",
    "        else:\n",
    "            shutil.copyfile(\n",
    "                dirPath + \"images/\" + imgname,\n",
    "                saveDir_trainValTest + \"/val/withlesion/\" + imgname,\n",
    "            )\n",
    "\n",
    "    for i in tqdm(range(len(x_test))):\n",
    "        line = x_test[i]\n",
    "        imgname = line.split(\" \")[0]\n",
    "        if not os.path.isfile(dirPath + \"images/\" + imgname):\n",
    "            print(\"PROBLEM\")\n",
    "        if \"nolesion\" in line:\n",
    "            shutil.copyfile(\n",
    "                dirPath + \"images/\" + imgname,\n",
    "                saveDir_trainValTest + \"/test/nolesion/\" + imgname,\n",
    "            )\n",
    "        else:\n",
    "            shutil.copyfile(\n",
    "                dirPath + \"images/\" + imgname,\n",
    "                saveDir_trainValTest + \"/test/withlesion/\" + imgname,\n",
    "            )\n",
    "\n",
    "print(\"Number of training images, no lesion: \", len(os.listdir(saveDir_trainValTest + \"train/nolesion/\")))\n",
    "print(\"Number of training images, with lesion: \", len(os.listdir(saveDir_trainValTest + \"train/withlesion/\")))\n",
    "print(\"Number of validation images, no lesion: \", len(os.listdir(saveDir_trainValTest + \"val/nolesion/\")))\n",
    "print(\"Number of validation images, with lesion: \", len(os.listdir(saveDir_trainValTest + \"val/withlesion/\")))\n",
    "print(\"Number of test images, no lesion: \", len(os.listdir(saveDir_trainValTest + \"test/nolesion/\")))\n",
    "print(\"Number of test images, with lesion: \", len(os.listdir(saveDir_trainValTest + \"test/withlesion/\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530c527f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train model\n",
    "if train_classifier:\n",
    "    util_classifier_pediatric.train_model(saveDir_trainValTest, nickname, nreps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0667c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load models\n",
    "saveDir00 = saveDir_trainValTest\n",
    "if config.FLOAT:\n",
    "    model_run_file = saveDir00 +'/float/'+'train.log'\n",
    "else:\n",
    "    model_run_file = saveDir00 +'/uint8/'+'train.log'\n",
    "model_run_file\n",
    "model_runs = [model_run_file]\n",
    "model_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81eed854",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the example ID  in test data\n",
    "test_log_list = []\n",
    "test_log_ID_list = []\n",
    "testDataDir_nolesion = saveDir_trainValTest + '/test/nolesion'\n",
    "print(testDataDir_nolesion)\n",
    "testDataDir_withlesion = saveDir_trainValTest +'/test/withlesion'\n",
    "for log_name in os.listdir(testDataDir_nolesion):\n",
    "    test_log_list.append(log_name)\n",
    "for log_name in os.listdir(testDataDir_withlesion):\n",
    "    test_log_list.append(log_name)\n",
    "for item in test_log_list:\n",
    "    test_log_ID_list.append(item.split(\"projection_DM\")[1].split('.npy')[0])\n",
    "    \n",
    "print(\"Number of test images:\", len(test_log_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81390f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if create_evaluations_dicts:\n",
    "    dict_dir = dirPath + '/dicts/'\n",
    "    print(dict_dir)\n",
    "    os.makedirs(dict_dir, exist_ok=True)\n",
    "    util_testing.run_dict_script(test_log_list[0:1], test_log_ID_list, model_runs, dict_dir,logDir='log_victre/',NEXAMPLES=len(test_log_ID_list)) #log_testing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
